# Enterprise Migration Plan: AWS to Cloudflare

**Version:** 1.0
**Date:** 2025-08-22
**Author:** Jules, Senior Cloud Architect

## 1. Executive Summary

This document outlines the comprehensive, enterprise-grade migration plan to transition the SyncWell application and its underlying infrastructure from Amazon Web Services (AWS) to Cloudflare's developer platform. The primary objectives of this migration are to eliminate AWS dependencies, leverage Cloudflare's global network for enhanced performance, simplify the operational model, and achieve significant, long-term cost efficiencies.

The current architecture is a sophisticated, event-driven system leveraging a wide array of AWS services, including Lambda, Fargate, DynamoDB, SQS, and API Gateway. The migration will involve a complete re-architecture of core components to align with Cloudflare's service offerings, such as Workers, R2, D1, and Durable Objects.

This plan details a phased approach designed to minimize risk and ensure business continuity. It begins with discovery and architectural design, proceeds through a proof-of-concept and incremental migration, and concludes with a final cutover and decommissioning of AWS resources. A significant focus is placed on the redesign of the data layer, moving from DynamoDB's NoSQL model to Cloudflare D1's relational model, which represents the most complex and high-risk aspect of this project.

By following this structured plan, we aim to achieve a seamless transition, resulting in a more performant, secure, and cost-effective platform for SyncWell's next stage of growth.

---

## 2. Phase 1: Discovery & Current-State Assessment

**Objective:** To create a complete and exhaustive audit of the current AWS architecture, dependencies, and cost drivers. This forms the baseline for all subsequent planning.

**Effort Estimate:** Low (2-3 weeks)

**Tasks:**

1.  **2.1. Automated Resource Inventory:**
    *   Use the AWS API/CLI and tools like AWS Config to generate a complete list of all deployed resources across all environments (production, staging).
    *   **Deliverable:** A machine-readable inventory of all EC2, Lambda, Fargate, S3, DynamoDB, ElastiCache, SQS, and other resources.

2.  **2.2. Architecture & Dependency Mapping:**
    *   Review the `06-technical-architecture.md` document and validate it against the live resource inventory.
    *   Create a detailed dependency graph illustrating all internal and external service communications, paying special attention to network egress points and third-party API calls.
    *   **Deliverable:** An up-to-date system architecture diagram and a corresponding dependency matrix.

3.  **2.3. Cost & Usage Analysis:**
    *   Analyze the `66-costs-model.md` document and cross-reference it with 6 months of AWS Cost Explorer data.
    *   Identify and rank the primary cost drivers (identified as Lambda, CloudWatch, API Gateway, and NAT Gateway).
    *   Quantify data transfer patterns (ingress, egress, inter-AZ).
    *   **Deliverable:** A detailed cost analysis report confirming the top 5 cost-driving services and usage patterns.

4.  **2.4. Performance & NFR Audit:**
    *   Review existing CloudWatch dashboards and metrics to baseline current performance against the NFRs defined in `06-technical-architecture.md`.
    *   Establish current P95/P99 latencies for key API endpoints and sync job durations.
    *   **Deliverable:** A performance baseline report.

**Success Criteria:**
*   All AWS resources are identified and documented.
*   A definitive, validated architecture diagram is produced.
*   The project team agrees on the top 5 cost drivers and their underlying usage metrics.

---

## 3. Phase 2: Cloudflare Service Mapping & Architecture Redesign

**Objective:** To design the new target architecture on Cloudflare, creating explicit mappings from AWS services and redesigning components where no direct equivalent exists.

**Effort Estimate:** High (4-6 weeks)

**Tasks:**

1.  **3.1. Service-to-Service Mapping:**
    *   Create a detailed mapping table for every AWS service to its Cloudflare equivalent.
    *   **Deliverable:** The table below.

| AWS Service | Cloudflare Service | Migration Notes & Required Redesign |
| :--- | :--- | :--- |
| **Compute** | | |
| AWS Lambda ("Hot Path") | Cloudflare Workers | Direct mapping. Logic can be ported. Runtimes differ (Node.js/Wasm vs. JVM). |
| AWS Fargate ("Cold Path") | Cloudflare Workers + Durable Objects | **Major Redesign.** Fargate's long-running nature must be replaced. Large tasks will be broken down and orchestrated by a Durable Object acting as a state machine. |
| AWS Step Functions | Cloudflare Durable Objects | **Major Redesign.** The state machine logic from Step Functions must be re-implemented within a Durable Object, which will manage state and trigger subsequent workers. |
| **Storage** | | |
| Amazon DynamoDB | Cloudflare D1 | **CRITICAL REDESIGN.** This is the highest-risk part of the migration. The single-table NoSQL design must be completely re-architected into a relational schema for D1 (SQL-based). All data access patterns must be rewritten. |
| Amazon S3 | Cloudflare R2 | Direct mapping. R2 is S3-compatible. Data can be migrated using the Cloudflare Migrator tool. |
| Amazon ElastiCache (Redis) | Cloudflare Workers KV / Durable Objects | For simple caching (`config##{userId}`), Workers KV is a good fit. For complex logic like rate-limiting, a Durable Object provides the required atomic operations. |
| **Networking** | | |
| API Gateway & CloudFront | Cloudflare Workers & CDN | Cloudflare Workers will serve as the API endpoints, running on the global CDN. This is a core Cloudflare strength. |
| AWS WAF | Cloudflare WAF | Direct mapping. Rules will need to be translated and re-implemented. |
| Route 53 | Cloudflare DNS | Direct mapping. DNS records will be migrated during the cutover phase. |
| VPC, NAT Gateway, Network Firewall | Cloudflare Zero Trust & Tunnels | The concept of a VPC disappears. Secure access to internal services will be managed via Cloudflare Tunnels and Zero Trust policies, providing a more modern, secure perimeter. |
| **Messaging** | | |
| Amazon SQS | Cloudflare Queues | Direct mapping for standard queues. FIFO queue logic needs to be handled at the application layer if required. |
| Amazon EventBridge | Cloudflare Queues + Worker | A fan-out pattern can be achieved by having a "dispatcher" Worker read from a central queue and push messages to multiple consumer queues. |
| Amazon SNS (Push Notifications) | Cloudflare Worker | A dedicated Worker will be created to directly call third-party push notification services like APNs and FCM. |
| **Security & Identity** | | |
| AWS IAM | Cloudflare Access (Zero Trust) | IAM roles and policies will be replaced with Cloudflare Access policies for authenticating both users and services. |
| AWS Secrets Manager | Cloudflare Worker Secrets | Direct mapping. Secrets will be encrypted and bound to Workers. |
| Firebase/Cognito Auth | Cloudflare Access | **Major Redesign.** The existing JWT validation logic in the Authorizer Lambda will be replaced by Cloudflare Access, which can be configured to validate tokens from third-party IdPs or issue its own. |
| **Observability** | | |
| CloudWatch & X-Ray | Workers Trace & Logging Integrations | Cloudflare provides tracing out of the box. Logs can be streamed to third-party services like Datadog, Sentry, or a custom logging endpoint. The tiered logging logic must be re-implemented. |
| **Configuration** | | |
| AWS AppConfig | R2/KV + Worker | Configuration data will be stored as JSON files in an R2 bucket. A Worker will read this configuration and can provide it to other workers, with caching for performance. |

2.  **3.2. Data Model Redesign for Cloudflare D1:**
    *   Analyze all DynamoDB access patterns from the `06-technical-architecture.md` document.
    *   Design a normalized, relational schema for D1 that can support these access patterns efficiently.
    *   This will involve creating tables for `Users`, `Connections`, `SyncConfigs`, etc., and defining foreign key relationships.
    *   **Deliverable:** A complete SQL schema for D1 and a document outlining the new data access patterns.

3.  **3.3. Orchestration Redesign with Durable Objects:**
    *   Redesign the Data Export and Data Import workflows (currently in Step Functions) using Durable Objects.
    *   The Durable Object will act as the orchestrator, holding the state of the job and invoking stateless Workers to perform each step (e.g., "fetch chunk," "format file").
    *   **Deliverable:** A sequence diagram and state transition model for the new Durable Object-based workflows.

**Success Criteria:**
*   The target Cloudflare architecture is fully designed and documented.
*   The new D1 database schema is finalized and peer-reviewed.
*   The Durable Object orchestration models for "cold path" jobs are approved.

---

## 4. Phase 3: Proof of Concept (PoC) / Pilot Migration

**Objective:** To validate the new architecture and key technical assumptions with a low-risk, isolated component of the system.

**Effort Estimate:** Medium (4-5 weeks)

**Tasks:**

1.  **4.1. Select PoC Candidate:**
    *   The **Data Import** feature is the ideal candidate. It's a self-contained, asynchronous "cold path" workflow that touches key new components (Workers, Durable Objects, R2, D1) but is not on the critical user-facing "hot path".

2.  **4.2. Build the PoC:**
    *   Implement the `DataImportStateMachine` logic using a Durable Object.
    *   Write Workers to handle file parsing and validation.
    *   Use R2 for file uploads and D1 to store job status (on the new relational schema).
    *   Set up Cloudflare Queues to trigger the final sync job.
    *   **Deliverable:** A fully functional Data Import pipeline running on Cloudflare infrastructure in a development environment.

3.  **4.3. Performance & Cost Benchmarking:**
    *   Run a series of load tests against the PoC pipeline.
    *   Measure latency, error rates, and resource consumption.
    *   Estimate the cost of the new Cloudflare implementation and compare it to the equivalent AWS Fargate/Step Functions cost.
    *   **Deliverable:** A PoC evaluation report detailing performance, cost, and lessons learned.

**Success Criteria:**
*   The Data Import PoC is successfully implemented and functional on Cloudflare.
*   Performance and cost benchmarks meet or exceed the targets set based on the AWS baseline.
*   The development team gains hands-on experience with the new Cloudflare stack.

---

## 5. Phase 4: Incremental Migration (By Component)

**Objective:** To migrate the system component by component, using a strangler fig pattern to gradually shift traffic from AWS to Cloudflare.

**Effort Estimate:** High (8-12 weeks)

**Migration Order (Prioritized by Risk and Dependency):**

1.  **5.1. Foundational Services (Non-functional):**
    *   **Observability:** Set up log streaming from Cloudflare to our chosen observability platform (e.g., Datadog).
    *   **CI/CD:** Update the CI/CD pipeline (GitHub Actions) to support deploying Workers, Durable Objects, and D1 schemas using Wrangler.
    *   **Security:** Configure Cloudflare WAF, Access, and Zero Trust policies.

2.  **5.2. "Cold Path" Migration (Data Export):**
    *   Migrate the Data Export workflow, leveraging the patterns and lessons learned from the PoC.
    *   This is the second "cold path" feature and further de-risks the migration of stateful orchestration.

3.  **5.3. "Hot Path" Backend Migration (The Core Sync Engine):**
    *   This is the most critical phase. The migration will be done endpoint-by-endpoint.
    *   **Strangler Fig Pattern:** Use Cloudflare Workers to proxy requests. Initially, the Worker will simply pass all traffic to the existing AWS API Gateway.
    *   **Endpoint-by-Endpoint Migration:**
        1.  Migrate the logic for a single, low-risk endpoint (e.g., `GET /v1/connections`) to a Cloudflare Worker.
        2.  Update the proxy Worker to route requests for this specific endpoint to the new Cloudflare implementation, while all other traffic continues to flow to AWS.
        3.  The new Worker will read from the **migrated D1 database**.
        4.  Repeat this process for all API endpoints, gradually "strangling" the old AWS API.
    *   The `POST /v1/sync-jobs` endpoint will be the last to migrate, as it triggers the core "hot path" logic.

**Success Criteria:**
*   All backend services are successfully deployed and running on Cloudflare.
*   At the end of this phase, 100% of API traffic is being served by Cloudflare Workers.
*   The AWS Lambda and Fargate compute services are handling zero production traffic.

---

## 6. Phase 5: Data Migration Strategy

**Objective:** To migrate all application data from AWS data stores (DynamoDB, S3) to Cloudflare (D1, R2) with zero data loss and minimal application downtime.

**Effort Estimate:** High (Concurrent with Phase 4)

**Tasks:**

1.  **6.1. Static Asset Migration (S3 to R2):**
    *   Use Cloudflare's `Super Slurper` or a custom script to perform a one-time copy of all static assets (e.g., provider icons) from the S3 bucket to the corresponding R2 bucket.
    *   This is a low-risk, offline task.

2.  **6.2. Transactional Data Migration (DynamoDB to D1):**
    *   This is a highly sensitive process that must be carefully orchestrated.
    *   **Step 1: Schema Creation:** Apply the new D1 SQL schema (from Phase 2) to the production D1 database.
    *   **Step 2: Initial Bulk Load:**
        *   Take a consistent snapshot of the DynamoDB table using Point-in-Time Recovery (PITR).
        *   Run a batch job (e.g., on Fargate or a local machine) that reads from the DynamoDB snapshot, transforms the data from NoSQL items to relational rows, and bulk-inserts it into the D1 database.
    *   **Step 3: Dual-Writing & Reconciliation:**
        *   As part of the "Hot Path" migration (Phase 4), modify the original AWS Lambda functions to **write to both DynamoDB and D1 simultaneously**. This ensures that the D1 database stays up-to-date with any changes made during the migration period.
        *   Run a periodic reconciliation script to find and fix any discrepancies between the two databases.
    *   **Step 4: Final Read Cutover:** Once the incremental migration of API endpoints is complete, all reads and writes will be exclusively handled by the Cloudflare Workers and D1 database. The dual-writing from AWS can be turned off.

**Success Criteria:**
*   All data from DynamoDB is successfully and verifiably migrated to D1.
*   A data integrity check (e.g., comparing row counts and checksums) passes.

---

## 7. Phase 6: Testing, Validation & Rollback Planning

**Objective:** To ensure the migrated system is fully functional, performant, and secure, and to have a clear rollback plan in case of critical failure.

**Effort Estimate:** Medium (Concurrent with Phases 3-5)

**Tasks:**

1.  **7.1. Automated Testing:**
    *   All existing unit and integration tests must be adapted and run against the new Cloudflare implementation.
    *   Write new integration tests specifically for Cloudflare services (e.g., testing Durable Object state transitions).

2.  **7.2. Performance & Load Testing:**
    *   Re-run the k6 load testing suite against the Cloudflare-hosted application.
    *   Validate that the system meets the NFRs for latency and throughput (3,000 RPS).

3.  **7.3. Security Audit:**
    *   Conduct a full security review of the new Cloudflare architecture.
    *   Validate WAF rules, Access policies, and secret management.
    *   Perform penetration testing against the new endpoints.

4.  **7.4. Rollback Plan:**
    *   **During Incremental Migration:** If a migrated endpoint on Cloudflare shows critical issues, the proxy Worker can be instantly reconfigured to route traffic back to the corresponding AWS endpoint.
    *   **Post-Cutover:** If a catastrophic issue is found after the full cutover, the primary rollback strategy is to switch DNS back to point to the AWS API Gateway. This is possible because the dual-writing strategy ensures the DynamoDB database remains up-to-date until the final decommissioning phase.

**Success Criteria:**
*   All automated tests pass.
*   The system meets all performance and security NFRs.
*   The rollback plan is documented, tested, and approved.

---

## 8. Phase 7: Cutover Strategy

**Objective:** To perform the final switchover of user traffic to the Cloudflare platform with minimal downtime.

**Effort Estimate:** Low (1-2 weeks preparation, <1 hour execution)

**Tasks:**

1.  **8.1. Pre-Cutover Checklist:**
    *   Verify all data has been migrated and reconciled (Phase 5).
    *   Confirm all tests have passed (Phase 6).
    *   Communicate a maintenance window to all stakeholders.

2.  **8.2. DNS Cutover:**
    *   The primary cutover mechanism is a DNS change.
    *   Lower the TTL on the main application DNS records to 60 seconds, 24 hours before the cutover window.
    *   During the maintenance window, update the DNS CNAME/A records in Cloudflare DNS to point traffic from the application's domain to the Cloudflare Worker endpoints instead of the AWS API Gateway.

3.  **8.3. Post-Cutover Monitoring:**
    *   Closely monitor Cloudflare dashboards and observability platforms for any anomalies in traffic, error rates, or performance.
    *   The project team will be on "war room" standby to execute the rollback plan if needed.

**Success Criteria:**
*   100% of production traffic is successfully routed to and served by the Cloudflare platform.
*   The system remains stable and performant post-cutover.
*   Downtime is kept within the planned maintenance window (target: < 15 minutes).

---

## 9. Phase 8: AWS Decommissioning & Governance

**Objective:** To completely eliminate AWS dependencies and costs, and establish new governance policies for the Cloudflare environment.

**Effort Estimate:** Medium (2-4 weeks)

**Tasks:**

1.  **9.1. Turn Off Dual-Writing:**
    *   Once the Cloudflare platform has been stable for a defined period (e.g., 7 days), disable the dual-writing logic in the (now idle) AWS Lambda functions.

2.  **9.2. Decommission AWS Resources:**
    *   **Step 1: Compute & Endpoints:** Shut down all AWS Lambda functions and Fargate tasks. Delete API Gateway endpoints.
    *   **Step 2: Databases:** After taking a final backup, delete the DynamoDB tables and ElastiCache for Redis clusters.
    *   **Step 3: Storage & Messaging:** Delete SQS queues and non-archival S3 buckets.
    *   **Step 4: Networking & Security:** Terminate all remaining AWS resources (VPCs, WAF, etc.).

3.  **9.3. Final Cost Analysis:**
    *   After one full month of running exclusively on Cloudflare, perform a final cost analysis.
    *   Compare the actual Cloudflare bill to the projected costs and the previous AWS bills.
    *   **Deliverable:** A final migration ROI and cost savings report.

4.  **9.4. Update Governance & Documentation:**
    *   Update all runbooks, architectural documents, and operational policies to reflect the new Cloudflare architecture.
    *   Establish cost monitoring and governance policies for Cloudflare.

**Success Criteria:**
*   All legacy AWS resources are terminated.
*   The final AWS bill is $0.
*   All project documentation is updated to reflect the new Cloudflare architecture.

---

## 10. Risk Management

| Risk ID | Risk Description | Probability | Impact | Mitigation Strategy |
| :--- | :--- | :--- | :--- | :--- |
| **MIG-R-01** | **Data Model Redesign Flaw:** The new D1 relational schema is inefficient or incorrect, leading to poor performance or data integrity issues. | **Medium** | **High** | Extensive data access pattern analysis in Phase 2; rigorous testing and peer review of the schema; performance testing the PoC against the new schema. |
| **MIG-R-02** | **Performance Regression:** The Cloudflare implementation, particularly Workers or D1, is slower than the AWS equivalent for specific workloads. | **Medium** | **Medium** | Establish a performance baseline in Phase 1; conduct rigorous load testing in Phase 6; tune Worker/D1 configurations based on results. |
| **MIG-R-03** | **Cost Overrun:** The actual Cloudflare costs are significantly higher than projected. | **Low** | **High** | Use the PoC to benchmark and refine cost models early; establish Cloudflare cost monitoring and alerts from day one. |
| **MIG-R-04** | **Vendor-Specific Logic:** The migration introduces deep dependencies on Cloudflare-specific features (e.g., Durable Objects), creating a new form of vendor lock-in. | **High** | **Medium** | **Accepted Risk.** This is a strategic trade-off made to gain the benefits of the Cloudflare platform. The focus is on a successful migration, not on building a cloud-agnostic system. |
| **MIG-R-05** | **Data Migration Failure:** The dual-writing or reconciliation process fails, leading to data loss or inconsistency. | **Low** | **Critical** | Implement robust data validation and checksums; run reconciliation scripts frequently; have a tested rollback plan to rely on the AWS data source. |

## 11. Project Governance & KPIs

*   **Project Lead:** Senior Cloud Architect
*   **Key Stakeholders:** CTO, Head of Engineering, Finance Lead
*   **Communication Cadence:** Weekly progress reports, bi-weekly stakeholder reviews.

### Milestones & Checkpoints

| Phase | Milestone | Checkpoint Gate |
| :--- | :--- | :--- |
| 1 | Discovery Complete | Go/No-Go decision based on validated baseline |
| 2 | Architecture Design Complete | CTO sign-off on the target Cloudflare architecture |
| 3 | PoC Complete & Evaluated | Go/No-Go decision for full migration based on PoC results |
| 4-6 | Incremental Migration Complete | All API traffic served by Cloudflare; all tests passed |
| 7 | DNS Cutover Complete | 100% of user traffic on Cloudflare |
| 8 | AWS Decommissioned | Final project completion; AWS bill is $0 |

### Key Performance Indicators (KPIs)

*   **Cost Reduction:** Target a **40-60% reduction** in monthly infrastructure spend compared to the AWS baseline (Nominal: ~$13k/mo).
*   **Latency Improvement:** Target a **20-30% reduction** in P99 API latency due to Cloudflare's global edge network.
*   **Reliability:** Maintain or exceed existing SLOs (99.9% uptime).
*   **Migration Timeline:** Complete the entire migration within **6 months**.
