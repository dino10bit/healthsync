# Technical Architecture Review: SyncWell

---

## 1. Summary of Findings

### Overall Maturity

The collection of documents represents a **mature and comprehensive** technical vision. The level of detail, particularly in `06-technical-architecture.md`, is commendable. The authors have clearly invested significant effort in thinking through scalability, resilience, and security for a large-scale (1M DAU) system. The adoption of modern, cloud-native patterns (serverless, IaC, multi-region HA) provides a strong foundation.

However, the documentation suite suffers from **significant inconsistencies** across documents, indicating a lack of centralized review and alignment. While individual documents are strong, they sometimes contradict each other on critical architectural decisions. The overall maturity is high, but the consistency is low, which introduces risk into the execution phase.

### Critical Findings

Three findings stand out as requiring immediate attention before any significant implementation work proceeds:

1.  **Critical - Contradictory Compute Strategy (Lambda vs. Fargate):** There is a fundamental contradiction across multiple documents regarding the core backend compute platform. `06-technical-architecture.md` and `16-performance-optimization.md` define a "unified AWS Lambda compute model" as the definitive MVP strategy. However, `05-data-sync.md` and `07-apis-integration.md` repeatedly reference and diagram "Worker Task (Fargate)". This is not a minor inconsistency; it represents two vastly different operational, performance, and cost models. The team must align on a single strategy immediately.
2.  **Critical - Flawed Concurrency & SLO Mismatch:** `16-performance-optimization.md` bases its critical concurrency projection of **15,000 concurrent Lambdas** on an *average* job duration of 5 seconds. However, the same document sets the P90 SLO for Lambda duration at **15 seconds**. If the P90 is 15s, the actual concurrency required to meet the 3,000 RPS target could be closer to 45,000, which has catastrophic implications for cost and technical feasibility. This mathematical inconsistency must be resolved.
3.  **Critical - Distributed Locking in Active-Active Setup:** `18-backup-recovery.md` specifies using an ElastiCache Global Datastore for distributed locking in an active-active, multi-region architecture. This is a well-known anti-pattern. The replication lag inherent in such a system can break the mutual exclusion guarantee of a lock, leading to race conditions and data corruption. This design flaw must be addressed.

---

## 2. Logical Flaws, Bugs, and Inconsistencies

| ID | Description | Impact/Severity | Recommendation |
| :--- | :--- | :--- | :--- |
| **L-01** | **Contradictory Compute Strategy (Lambda vs. Fargate):** `06-technical-architecture.md` and `16-performance-optimization.md` mandate a unified AWS Lambda model, while `05-data-sync.md` and `07-apis-integration.md` reference and diagram AWS Fargate for worker tasks. | **Critical** | The technical leadership must make a definitive decision on the MVP compute strategy and update all documentation to reflect this single source of truth. |
| **L-02** | **Mismatch in Concurrency Calculation vs. SLO:** The concurrency projection of 15,000 is based on a 5s average Lambda duration, but the P90 SLO is 15s. The math is inconsistent. | **Critical** | Re-evaluate the concurrency model. Either the SLO must be tightened significantly, or the concurrency projections (and associated cost/feasibility analysis) must be revised upwards based on the 15s P90 target. |
| **L-03** | **Strava Cannot Sync "Steps":** `06-technical-architecture.md` provides an example API call to sync "steps" to Strava. However, `07-apis-integration.md` correctly notes that the Strava API does not support daily step data. | **High** | Remove all incorrect references and examples of syncing step data to Strava. Ensure the `SyncConfig` logic prevents users from creating this invalid mapping. |
| **L-04**| **Inconsistent `Request Lambda` vs. Direct Integration:** `05-data-sync.md` mentions a `Request Lambda` initiating historical syncs, while `06-technical-architecture.md` correctly emphasizes using direct API Gateway integrations to Step Functions to reduce cost and latency. | **Medium** | Update `05-data-sync.md` to be consistent with the direct integration pattern described in the main architecture document. The diagrams are correct, but the text is not. |
| **L-05** | **Sync Error Notification Trigger Logic:** `29-notifications-alerts.md` states that a "Sync Error" notification is triggered by any message arriving in the DLQ. However, `17-error-handling.md` specifies a `DLQAnalyzer` that can automatically redrive certain known errors. | **Medium** | The notification trigger logic is flawed. A notification should only be sent *after* the `DLQAnalyzer` has confirmed the failure is persistent and requires user action, not on the raw DLQ event. |
| **L-06** | **Duplicate `DataProvider` SDK Paragraph:** `07-apis-integration.md` has a duplicated paragraph in Section 2.3. | **Low** | This is a minor editorial issue. Remove the duplicated paragraph to improve document clarity. |
| **L-07** | **Duplicate Security Section:** `19-security-privacy.md` has a duplicated "Access Control and Least Privilege" section at the end of the document. | **Low** | Remove the duplicate section to clean up the document. |

---

## 3. Clarity, Completeness, and Ambiguity

| ID | Description | Impact/Severity | Recommendation |
| :--- | :--- | :--- | :--- |
| **C-01** | **Missing Diagrams in Performance Document:** `16-performance-optimization.md` explicitly references `[Diagram] Caching Architecture` and `[Diagram] Job Chunking Flow`, but they are not present. | **Medium** | The author must create and embed these diagrams. Visuals are essential for understanding these complex flows. |
| **C-02** | **Missing Diagrams/Mockups in Notifications Document:** `29-notifications-alerts.md` references several missing visuals, including a data flow diagram and screen mockups. | **Medium** | The author must provide the referenced diagrams and mockups to ensure the technical and product vision is clearly communicated. |
| **C-03** | **Undefined `correlationId` to `userId` Mapping:** `17-error-handling.md` and `19-security-privacy.md` mandate logging with a `correlationId` instead of a `userId` for privacy. However, they fail to specify *how* the "break-glass" procedure maps a `correlationId` back to a user for debugging. | **High** | This is a critical gap. The design of the `SyncWellBreakGlassIndex` in `19-security-privacy.md` is a good start, but it needs to be explicitly referenced in the logging and error handling documents as the definitive mechanism for this lookup. |
| **C-04** | **Arbitrary Time Buffers:** The delta sync algorithm in `05-data-sync.md` uses a `+/- 5 minute` buffer for fetching destination data, and the conflict detection uses a `60 second` overlap. These values feel arbitrary. | **Low** | Justify the rationale for these specific time windows or state that they are configurable parameters that will be tuned based on testing. |
| **C-05** | **Undefined Manual Account Recovery:** `18-backup-recovery.md` mentions a "potential manual account recovery process" if a user loses their social sign-in. This process is undefined. | **Medium** | Define this process. What are the steps? How is user identity verified to prevent account takeover? This has significant security and operational implications. |
| **C-06** | **Unspecified DLQ Analyzer Implementation:** `17-error-handling.md` proposes a `DLQAnalyzer` Lambda, but doesn't specify how its ruleset (for identifying known errors) will be managed. | **Medium** | Specify the implementation for the ruleset. Will it be hard-coded `if/else` logic, or a more maintainable approach like a configuration file in S3 or a rules engine? |
| **C-07** | **Ambiguous Cache Hit Rate SLO:** The `> 90%` cache hit rate SLO in `16-performance-optimization.md` is ambiguous. It's unclear if this applies to the API Gateway authorizer cache, the ElastiCache cluster, or both. | **Low** | Clarify the scope of this SLO. It may be better to define separate, more specific SLOs for each caching layer, as they have different performance characteristics and impact. |
| **C-08** | **Missing Notification Rate-Limiting Details:** `29-notifications-alerts.md` mentions rate-limiting notifications as a risk mitigation, but provides no implementation details. | **Medium** | This is a critical resilience feature. The document should detail how this will be implemented. Does it use the main ElastiCache cluster? What are the default limits? |
| **C-09** | **Missing EventBridge DLQ Monitoring Plan:** `17-error-handling.md` mentions a DLQ for the EventBridge rule as a defense-in-depth measure, but the operational runbook only covers the SQS DLQ. | **Low** | The runbook should be updated to include the process for monitoring and handling messages that fail delivery from EventBridge to SQS. |
| **C-10** | **Historical Sync Chunking Strategy:** The plan to chunk historical syncs by a fixed time period (e.g., one month) is too simplistic. A month for a very active user could still be a massive job that times out a Lambda. | **Medium** | The chunking strategy should be more dynamic. Propose a more robust algorithm, such as chunking by a maximum number of records or adapting the time window based on the user's historical activity volume. |
| **C-11** | **Generic Error Handling in Dictionary:** The error code dictionary in `17-error-handling.md` focuses on known, specific errors. It's unclear how unexpected or unknown backend failures are communicated to the client. | **Low** | Define a generic error code (e.g., `INTERNAL_SERVER_ERROR`) in the dictionary that the client can use to display a standard "Something went wrong" message. |
| **C-12** | **Missing Justification for Cross-Cloud Notifications:** `29-notifications-alerts.md` proposes a complex AWS->Firebase cross-cloud architecture for push notifications without justifying why this is superior to a simpler single-cloud approach. | **Medium** | Provide a clear rationale for this architectural choice, explaining what benefits outweigh the added complexity, latency, and security considerations of a cross-cloud integration. |

---

## 4. Technical Feasibility Assessment

| ID | Description | Impact/Severity | Recommendation |
| :--- | :--- | :--- | :--- |
| **F-01** | **15,000+ Concurrent Lambdas:** The scale of concurrency required (15,000-45,000) is technically achievable but presents significant financial and operational risks. The documents acknowledge this, which is good. | **High** | The "Mandatory Feasibility Actions" listed in `16-performance-optimization.md` are not just recommendations; they are critical path prerequisites. The project should be considered blocked until a detailed cost model is approved and a proof-of-concept load test has validated the downstream dependencies. |
| **F-02** | **Cache Failure RTO is Too Long:** The 60-minute RTO for a manual promotion of a failed ElastiCache cluster is too long. `06-technical-architecture.md` implies this would cause a significant service degradation (e.g., pausing all syncs) for up to an hour. | **High** | Re-evaluate this RTO. Is a 60-minute partial outage acceptable? Investigate automating the failover process for the ElastiCache Global Datastore to dramatically reduce the RTO. |
| **F-03** | **Data Corruption Restore Plan:** The manual PITR process for DynamoDB described in `18-backup-recovery.md` is high-risk. Identifying the precise moment of corruption to restore to is extremely difficult in a live system. | **Medium** | The runbook for this process needs to be much more detailed. It must include the procedure for identifying the restore point and acknowledge the potential for data loss of transactions that occurred between the corruption and the restore. The link to using AWS AppConfig for re-pointing to the new table should be explicit. |
| **F-04** | **Ambitious Crash-Free Rate:** The 99.9% crash-free user rate target in `17-error-handling.md` is very ambitious for a new app, especially on Android. | **Low** | Frame this as an aspirational goal rather than a hard launch requirement. A lower, more realistic initial target (e.g., 99.5%) might be more appropriate for the MVP. |
| **F-05** | **Operational Overhead of `DataProvider` SDK:** `07-apis-integration.md` proposes packaging the `DataProvider` SDK as a private Maven package. This is a good practice but adds overhead. | **Low** | For an MVP, consider if keeping the SDK as a shared module in a monorepo would be simpler and faster, deferring the packaging complexity until the team grows. This is a trade-off question for the author. |
| **F-06**| **Manual Break-Glass Process:** The PR-based workflow for break-glass debugging is clever but may be operationally cumbersome and slow, impacting support response times. | **Medium** | Acknowledge this friction. While acceptable for an MVP, the plan to build a dedicated internal tool post-launch should be a high-priority follow-up item. |

---

## 5. Risk and Gap Analysis

### Security Risks
| ID | Description | Impact/Severity | Recommendation |
| :--- | :--- | :--- | :--- |
| **S-01** | **Distributed Locking with Replicated Cache:** Using ElastiCache Global Datastore for distributed locking in an active-active setup is a critical design flaw. Replication lag can cause multiple regions to acquire the same lock, leading to race conditions and data corruption. | **Critical** | This design must be changed. Either designate a single region for all locking operations (sacrificing active-active for this one function) or use a database transaction with conditional writes in DynamoDB to manage the lock state, which provides stronger consistency guarantees. |
| **S-02** | **Break-Glass Index TTL:** The 24-hour TTL on the `SyncWellBreakGlassIndex` is a strong privacy control but may be too short for practical support operations, especially over a weekend. | **Medium** | The author should justify this specific duration. Consider making the TTL configurable or extending it to a slightly longer period (e.g., 72 hours) as a pragmatic compromise between privacy and supportability. |
| **S-03** | **Certificate Pinning Deferral:** The decision to defer certificate pinning is pragmatic, but it means the application is foregoing a layer of defense against sophisticated MitM attacks. | **Low** | This is an acceptable risk for an MVP. The decision should be documented and periodically reviewed as the product's risk profile evolves. |
| **S-04**| **Runtime Error for Read-Only `pushData`:** `07-apis-integration.md` states that calling `pushData` on a read-only provider will throw a `NotImplementedError`. This is a runtime failure. | **Low** | The core `SyncManager` should proactively check the provider's `capabilities` set *before* attempting to call `pushData`. Failing early is better than relying on the provider implementation to throw an exception. |

### Operational Risks
| ID | Description | Impact/Severity | Recommendation |
| :--- | :--- | :--- | :--- |
| **O-01** | **No Fallback for Trial Expiry Notification:** The "Trial Ending" notification is scheduled locally on the client. If the user uninstalls and reinstalls, this critical business notification is lost. | **Medium** | Implement a backend-driven fallback mechanism. For example, have a scheduled daily job that checks for users whose trials are expiring soon and sends a push notification if one hasn't already been acknowledged. |
| **O-02** | **Manual DLQ Archiving:** The runbook in `17-error-handling.md` suggests that an engineer should manually archive DLQ messages before handling them. This step could be easily forgotten in a high-pressure situation. | **Low** | Automate this. The `DLQAnalyzer` Lambda should be responsible for archiving every message it receives to S3 as its very first step, *before* any triage logic is run. This guarantees no message is ever lost. |
| **O-03**| **No Integration of Step Functions into Main Dashboard:** `17-error-handling.md` praises the observability of Step Functions but doesn't mention how this will be integrated with the primary Grafana dashboard. | **Low** | To provide a single pane of glass for operators, ensure that key Step Functions execution metrics (e.g., success rate, duration) are exported to CloudWatch and included in the main Grafana dashboards. |
| **O-04**| **Circuit Breaker Defaults:** The default failure thresholds for the circuit breaker in `07-apis-integration.md` are not justified. | **Low** | State that these are placeholder values and must be tuned for each provider based on observed stability and load testing. |

### "Unknown Unknowns" & Alternative Approaches
| ID | Description | Impact/Severity | Recommendation |
| :--- | :--- | :--- | :--- |
| **U-01** | **What if the "viral user" is a write-heavy user?** The "hot table" strategy in `06-technical-architecture.md` works well for isolating a read-heavy user. But what if a user's write traffic is so high it threatens to exhaust the partition's throughput? | **Medium** | The document should acknowledge this scenario. While the "hot table" is still the first line of defense, the document should explicitly state that if write-sharding is ever needed, it would require a significant architectural change and should be considered a major project. |
| **U-02** | **Alternative to cross-cloud notifications:** The AWS->Firebase notification architecture is complex. An alternative would be to have an AWS Lambda function use the FCM API directly, keeping the entire backend within a single cloud provider. | **Medium** | The author should be asked to consider this alternative. What are the specific trade-offs? Is the decoupling worth the added complexity? |
| **U-03** | **What if a user wants to merge accounts?** The data model is strictly partitioned by `USER#{userId}`. What happens if a user accidentally creates two accounts (e.g., one with Google, one with Apple) and wants to merge them? | **Low** | The current architecture makes this nearly impossible. Acknowledge that account merging is not supported and would require a complex, manual engineering process. This should be a known limitation. |
| **U-04** | **Alternative to KMP on Backend:** The plan to use the KMP/JVM module on the backend Lambda is good for code reuse. However, was a "backend-for-frontend" (BFF) approach considered, where the backend is written in a separate, more performant runtime (like Go or Rust) and only shares the canonical data models with the client? | **Low** | This is a question to gauge the depth of architectural exploration. The current KMP approach is valid, but understanding what alternatives were considered is valuable. |

### Dependency Risks
| ID | Description | Impact/Severity | Recommendation |
| :--- | :--- | :--- | :--- |
| **D-01**| **Unstable Third-Party APIs:** `07-apis-integration.md` has a good section on managing unstable APIs with circuit breakers and feature flags. This is a well-understood risk. | **High** | The mitigation strategies are sound. The key will be rigorous implementation and disciplined operational monitoring of each provider's specific error rates. |
| **D-02**| **Firebase/Google Cloud Dependency:** The use of Firebase Authentication introduces a hard dependency on Google Cloud. An outage in Firebase Auth could prevent all users from logging in, even if the AWS backend is healthy. | **Medium** | This is an accepted trade-off for the superior SDKs and developer experience of Firebase. The risk should be formally documented and accepted by the product owner. |
| **D-03**| **Open Source Library Vulnerabilities:** The plan to use Snyk/Dependabot for scanning is a strong mitigation for supply chain attacks. | **Medium** | This process must be strictly enforced. The CI/CD pipeline must be configured to fail the build if a new critical or high-severity vulnerability is detected. |
