---
title: "PRD Section 39: Performance Monitoring & KPIs"
migrated: true
---
## Dependencies

### Core Dependencies
- `./16-performance-optimization.md` - Performance Optimization Strategy
- `./23-analytics.md` - Analytics & Metrics Tracking
- `./22-maintenance.md` - Maintenance & Post-Launch Operations (SRE)

### Strategic / Indirect Dependencies
- `../architecture/05-data-sync.md` - Data Sync & Conflict Resolution
- `./25-release-management.md` - Release Management & Versioning
- `./41-metrics-dashboards.md` - Analytics Dashboard Design

---

# PRD Section 39: Performance Monitoring & KPIs

## 1. Executive Summary

This document specifies the dashboards and Key Performance Indicators (KPIs) for SyncWell. While `16-performance-optimization.md` defined the strategy, this document specifies the *exact* metrics we will track. The goal is to create actionable dashboards that provide a comprehensive, at-a-glance view of the application's performance health for the **engineering and product teams**.

## 2. Dashboards

The following dashboards will be created and maintained in Grafana and Firebase.

| Priority | Dashboard Name | Audience | Location |
| :--- | :--- | :--- | :--- |
| **P0** | **Backend Health** | On-call Engineers, SRE | [Grafana Link](https://grafana.syncwell.com/d/backend-health) |
| **P1** | **Sync Health & KPIs** | Product & Engineering Leads | [Grafana Link](https://grafana.syncwell.com/d/sync-health) |
| **P2** | **Mobile Performance**| Mobile Engineers | [Firebase Console](https://console.firebase.google.com/u/0/project/syncwell/performance/dashboard) |

Release events will be automatically added as annotations to all Grafana dashboards. This will be automated via a `grafana-cli` command in a final step of the GitHub Actions deployment pipeline.

## 3. Custom Metric Definitions

To ensure consistency, all custom backend metrics published to CloudWatch will use the **`SyncWell/Backend`** namespace.

| Metric Name | Dimensions | Unit | Description |
| :--- | :--- | :--- | :--- |
| `WebhookReceived` | `Provider` | Count | Emitted by the webhook ingress Lambda each time a webhook is successfully received and authenticated. |
| `SyncJobRequested` | `Source` (e.g., `manual`, `webhook`) | Count | Emitted when a sync job is placed into the SQS queue. |
| `SyncJobCompleted` | `Provider`, `Status` (`SUCCESS` or `FAILURE`) | Count | Emitted by the Fargate worker when a sync job is completed. |
| `ManualSyncLatency`| `Provider` | Milliseconds | The time delta between a `SyncJobRequested` and `SyncJobCompleted` event for a manual sync. |
| `AdaptivePollingCadence`| `Provider` | Seconds | The calculated delay for the next poll for a given provider. Published by the adaptive polling scheduler. |

## 4. The Dashboards

### 4.1. P0: Backend Health Dashboard (Grafana)
This dashboard is for real-time, critical infrastructure monitoring.

| Widget Title | Chart Type | Metric(s) | Data Source |
| :--- | :--- | :--- | :--- |
| **API Gateway Latency (P99)**| Time Series | `Latency` | AWS CloudWatch |
| **API Gateway Errors (5xx)**| Time Series | `5xxError` count | AWS CloudWatch |
| **Fargate Worker CPU/Memory**| Time Series | `CPUUtilization`, `MemoryUtilization` | AWS CloudWatch |
| **SQS Hot Path Queue Depth**| Time Series | `ApproximateNumberOfMessagesVisible` | AWS CloudWatch |
| **DynamoDB Throttled Requests**| Time Series | `ReadThrottleEvents`, `WriteThrottleEvents` | AWS CloudWatch |

### 4.2. P1: Sync Health & KPIs Dashboard (Grafana)
This dashboard provides a holistic view of the end-to-end sync process and product KPIs.

| Widget Title | Chart Type | Metric(s) | Data Source |
| :--- | :--- | :--- | :--- |
| **Sync Success Rate (24h)**| Gauge | `SyncJobCompleted` where `status='SUCCESS'` / `SyncJobRequested` | Custom Metrics |
| **Sync Failure Rate by Provider**| Bar Chart | `SyncJobCompleted` where `status='FAILURE'`, grouped by `Provider` | Custom Metrics |
| **Manual Sync Latency (P95)**| Time Series | `ManualSyncLatency` | Custom Metrics |
| **Dead-Letter Queue Size** | Big Number | `ApproximateNumberOfMessagesVisible` for the DLQ | AWS CloudWatch |
| **Time Since Last Webhook**| Big Number | Calculated in Grafana: `time() - last(WebhookReceived)` | Custom Metrics |

### 4.3. P2: Mobile Performance Dashboard (Firebase)
This dashboard focuses on the health of the user-facing mobile application. Metrics are generated by the Firebase Performance Monitoring SDK integrated into the KMP module.

| Widget Title | Chart Type | Metric(s) | SLO Target | Rationale |
| :--- | :--- | :--- | :--- | :--- |
| **Crash-Free Users (24h)**| Gauge | `crashlytics.crash_free_users_rate` | > 99.9% | A core indicator of app stability and user trust. |
| **App Start Time (P90)**| Time Series | `performance.app_start_time` | < 2.0s | A slow app start is a major source of user frustration. |
| **Version Adoption**| Donut Chart | `analytics.users_by_app_version` | > 90% on latest version within 14 days | This aggressive goal is to minimize the support burden and ensure users get bug fixes quickly. |

## 5. Alerting Configuration

Alerts are routed from CloudWatch via SNS to the **`#alerts-backend`** Slack channel and the **`SyncWell-Backend-P1`** PagerDuty service.

| Alert Name | Metric | Threshold | Period | Eval Periods |
| :--- | :--- | :--- | :--- | :--- |
| **High API Gateway P99 Latency**| `Latency` (API Gateway) | > 500ms | 5 min | 2 |
| **API Gateway 5xx Error Spike**| `5xxError` | > 1% | 5 min | 1 |
| **Fargate CPU High** | `CPUUtilization` | > 80% | 15 min | 2 |
| **SQS Queue Depth High** | `ApproximateNumberOfMessagesVisible` | > 1000 | 10 min | 3 |
| **DLQ Has Messages** | `ApproximateNumberOfMessagesVisible` (DLQ) | > 0 | 1 min | 1 |
| **DynamoDB Throttling** | `ReadThrottleEvents` or `WriteThrottleEvents` | > 10 | 5 min | 1 |

## 6. Risk Analysis

| Risk ID | Risk Description | Probability | Impact | Mitigation Strategy |
| :--- | :--- | :--- | :--- | :--- |
| **R-101** | A bug in our instrumentation leads to inaccurate metrics, causing us to make bad product or technical decisions. | Medium | High | Key business metrics (e.g., SyncSuccessRate) must be validated with automated end-to-end tests that confirm the metric is emitted correctly. |
| **R-102** | Poorly configured or overly sensitive alerts create "alert fatigue," causing engineers to ignore real issues. | High | Medium | A quarterly review of all P1 alerts will be conducted by the SRE team to ensure they are still relevant and have a low false-positive rate. Any alert that fires more than 3 times a week without a corresponding incident is a candidate for re-evaluation. |
